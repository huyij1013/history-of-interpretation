{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgnQr_k9zqe_"
   },
   "source": [
    "## A Visual History of Interpretation in Image Recognition\n",
    "\n",
    "This notebook reproduces the history-of-interpretation [blog post](https://gradio.app/blog/interpretation-history), by the [Gradio](https://github.com/gradio-app/gradio) team. We relied heavily on [PAIR-code's implementation](https://github.com/PAIR-code/saliency) of the papers. \n",
    "\n",
    "Find the colab version [here](https://colab.research.google.com/drive/1IxhImCFknNMctIonSo98nkco2ufKmfdj?usp=sharing). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMSg9kP70gjF"
   },
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUQRh_OYv8lZ",
    "outputId": "43dc915f-c5a1-440b-ee42-5c54ff653901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\r\n",
      "You should consider upgrading via the '/Users/aliabdalla/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-slim gradio wget -q\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tf_slim as slim\n",
    "import sys\n",
    "import inception_v3\n",
    "import saliency\n",
    "import requests\n",
    "import gradio as gr\n",
    "import wget\n",
    "import tarfile\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "if not os.path.exists('inception_v3.ckpt'):\n",
    "    wget.download(\"http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\")\n",
    "    tar = tarfile.open(\"inception_v3_2016_08_28.tar.gz\")\n",
    "    tar.extractall()\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYgIxHOd05p7"
   },
   "source": [
    "### Setting up the graph, and adding a logit tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QO4Zw7ngwBvO",
    "outputId": "6b05948a-2455-4713-ee1e-70bca985437b"
   },
   "outputs": [],
   "source": [
    "ckpt_file = './inception_v3.ckpt'\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    images = tf.placeholder(tf.float32, shape=(None, 299, 299, 3))\n",
    "\n",
    "    with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n",
    "        _, end_points = inception_v3.inception_v3(images, is_training=False, num_classes=1001)\n",
    "\n",
    "        # Restore the checkpoint\n",
    "        sess = tf.Session(graph=graph)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, ckpt_file)\n",
    "\n",
    "    # Construct the scalar neuron tensor.\n",
    "    logits = graph.get_tensor_by_name('InceptionV3/Logits/SpatialSqueeze:0')\n",
    "    neuron_selector = tf.placeholder(tf.int32)\n",
    "    y = logits[0][neuron_selector]\n",
    "\n",
    "    # Construct tensor for predictions.\n",
    "    prediction = tf.argmax(logits, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zn4GvI_a1LLg"
   },
   "source": [
    "### Initializing and creating the different saliency methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8kMHuXi0zUtV",
    "outputId": "ed2958c2-b0c1-4cc7-9353-aa9071c1563f"
   },
   "outputs": [],
   "source": [
    "gradients = saliency.GradientSaliency(graph, sess, y, images)\n",
    "guided = saliency.GuidedBackprop(graph, sess, y, images)\n",
    "integrated = saliency.IntegratedGradients(graph, sess, y, images)\n",
    "blur_ig = saliency.BlurIG(graph, sess, y, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-Ww37lyF1i1r"
   },
   "outputs": [],
   "source": [
    "def vanilla_gradients(image):\n",
    "    image = image / 127.5 - 1.0\n",
    "    prediction_class = sess.run(prediction, feed_dict = {images: [image]})[0]\n",
    "    vanilla_mask_3d = gradients.GetMask(image, feed_dict = {neuron_selector: prediction_class})\n",
    "    vanilla_mask_grayscale = saliency.VisualizeImageGrayscale(vanilla_mask_3d)\n",
    "    return vanilla_mask_grayscale.tolist()\n",
    "\n",
    "def smoothgrad(image):\n",
    "    image = image / 127.5 - 1.0\n",
    "    prediction_class = sess.run(prediction, feed_dict = {images: [image]})[0]\n",
    "    smoothgrad_mask_3d = gradients.GetSmoothedMask(image, feed_dict = {neuron_selector: prediction_class})\n",
    "    smoothgrad_mask_grayscale = saliency.VisualizeImageGrayscale(smoothgrad_mask_3d)\n",
    "    return smoothgrad_mask_grayscale.tolist()\n",
    "\n",
    "def guided_backprop(image):\n",
    "    image = image / 127.5 - 1.0\n",
    "    prediction_class = sess.run(prediction, feed_dict = {images: [image]})[0]\n",
    "    vanilla_guided_backprop_mask_3d = guided.GetMask(\n",
    "    image, feed_dict = {neuron_selector: prediction_class})\n",
    "    vanilla_mask_grayscale = saliency.VisualizeImageGrayscale(vanilla_guided_backprop_mask_3d)\n",
    "    return vanilla_mask_grayscale.tolist()\n",
    "\n",
    "def integrated_smoothgrad(image):\n",
    "    image = image / 127.5 - 1.0\n",
    "    prediction_class = sess.run(prediction, feed_dict = {images: [image]})[0]\n",
    "    baseline = np.zeros(image.shape)\n",
    "    baseline.fill(-1)\n",
    "    smoothgrad_integrated_gradients_mask_3d = integrated.GetSmoothedMask(\n",
    "    image, feed_dict = {neuron_selector: prediction_class}, x_steps=25, x_baseline=baseline)\n",
    "    smoothgrad_mask_grayscale = saliency.VisualizeImageGrayscale(smoothgrad_integrated_gradients_mask_3d)\n",
    "    return smoothgrad_mask_grayscale.tolist()\n",
    "\n",
    "def blur_IG_vanilla(image):\n",
    "    image = image / 127.5 - 1.0\n",
    "    prediction_class = sess.run(prediction, feed_dict = {images: [image]})[0]\n",
    "    baseline = np.zeros(image.shape)\n",
    "    baseline.fill(-1)\n",
    "\n",
    "    blur_ig_mask_3d = blur_ig.GetMask(\n",
    "    image, feed_dict = {neuron_selector: prediction_class})\n",
    "\n",
    "    blur_ig_mask_grayscale = saliency.VisualizeImageGrayscale(blur_ig_mask_3d)\n",
    "    return blur_ig_mask_grayscale.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARNjzPA92unC"
   },
   "source": [
    "### Setting up classifier and Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 813
    },
    "id": "SVuV9DSVwJIv",
    "outputId": "b9473743-b624-4229-ea76-b7cc9f2978ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96116736/96112376 [==============================] - 2s 0us/step\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gradio/interface.py:136: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gradio/interface.py:137: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "This share link will expire in 6 hours. If you need a permanent link, email support@gradio.app\n",
      "Running on External URL: https://42271.gradio.app\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"https://42271.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdfc5bd3a20>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>,\n",
       " 'http://127.0.0.1:7860/',\n",
       " 'https://42271.gradio.app')"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download human-readable labels for ImageNet.\n",
    "inception_net = tf.keras.applications.InceptionV3() # load the model\n",
    "\n",
    "# Download human-readable labels for ImageNet.\n",
    "response = requests.get(\"https://git.io/JJkYN\")\n",
    "labels = response.text.split(\"\\n\")\n",
    "\n",
    "\n",
    "def classify_image(inp):\n",
    "    inp = inp.reshape((-1, 299, 299, 3))\n",
    "    inp = tf.keras.applications.inception_v3.preprocess_input(inp)\n",
    "    prediction = inception_net.predict(inp).flatten()\n",
    "    return {labels[i]: float(prediction[i]) for i in range(1000)}\n",
    "\n",
    "image = gr.inputs.Image(shape=(299, 299, 3))\n",
    "label = gr.outputs.Label(num_top_classes=3)\n",
    "\n",
    "examples = [[\"doberman.png\"], [\"dog.png\"]]\n",
    "\n",
    "gr.Interface(classify_image, image, label, capture_session=True, examples=examples,\n",
    "             allow_flagging=False).launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhqG3PGL28MC"
   },
   "source": [
    "### Leave-One-Out\n",
    "Default out of the box interpretation in Gradio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "eILloho93Lgj",
    "outputId": "cdf11378-5117-4e41-d7f2-7b887779f560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "This share link will expire in 6 hours. If you need a permanent link, email support@gradio.app\n",
      "Running on External URL: https://10479.gradio.app\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"https://10479.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdfb52feef0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>,\n",
       " 'http://127.0.0.1:7863/',\n",
       " 'https://10479.gradio.app')"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(classify_image, image, label, capture_session=True, interpretation=\"default\", examples=examples,\n",
    "             allow_flagging=False).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2Ccovnf3L7Z"
   },
   "source": [
    "### Vanilla Gradient Ascent [2009 and 2013]\n",
    "\n",
    "Paper: [Visualizing Higher-Layer Features of a Deep Network (2009)](https://www.researchgate.net/profile/Aaron_Courville/publication/265022827_Visualizing_Higher-Layer_Features_of_a_Deep_Network/links/53ff82b00cf24c81027da530.pdf)\n",
    "\n",
    "Paper: [Visualizing Image Classification Models and Saliency Maps (2013)](https://arxiv.org/abs/1312.6034)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "G_qQdAK-5AzE",
    "outputId": "028ae59e-b120-4ca7-e040-2ac20d9ac25d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "This share link will expire in 6 hours. If you need a permanent link, email support@gradio.app\n",
      "Running on External URL: https://16147.gradio.app\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"https://16147.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdfb24f9160>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>,\n",
       " 'http://127.0.0.1:7864/',\n",
       " 'https://16147.gradio.app')"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(classify_image, image, label, capture_session=True, interpretation=vanilla_gradients, examples=examples,\n",
    "             allow_flagging=False).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOTBmmsL29sJ"
   },
   "source": [
    "### Guided Back-Propogation [2014]\n",
    "\n",
    "Paper: [Striving for Simplicity: The All Convolutional Net (2014)](https://arxiv.org/abs/1412.6806)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "fQ5kKIDG5ETO",
    "outputId": "eaa14d82-d839-4625-d031-e184399578ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "This share link will expire in 6 hours. If you need a permanent link, email support@gradio.app\n",
      "Running on External URL: https://41416.gradio.app\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"https://41416.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdfb0c32160>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>,\n",
       " 'http://127.0.0.1:7865/',\n",
       " 'https://41416.gradio.app')"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(classify_image, image, label, capture_session=True, interpretation=guided_backprop, examples=examples,\n",
    "             allow_flagging=False).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0o9xIJY29zL"
   },
   "source": [
    "### SmoothGrad [2017]\n",
    "\n",
    "Paper: [SmoothGrad: removing noise by adding noise (2017)](https://arxiv.org/abs/1706.03825)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "bs0h9zum5E9-",
    "outputId": "9895880d-003f-4cee-eee5-289ae2032483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "This share link will expire in 6 hours. If you need a permanent link, email support@gradio.app\n",
      "Running on External URL: https://35400.gradio.app\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"https://35400.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdfb53d38d0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>,\n",
       " 'http://127.0.0.1:7866/',\n",
       " 'https://35400.gradio.app')"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(classify_image, image, label, capture_session=True, interpretation=smoothgrad, examples=examples,\n",
    "             allow_flagging=False).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15aYXFcz292B"
   },
   "source": [
    "### Integrated Gradients [2017]\n",
    "\n",
    "Paper: [Axiomatic Attribution for Deep Networks (2017)](https://arxiv.org/abs/1703.01365)\n",
    "\n",
    "**Note**: This method is *very* slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "NwUYghZO5Fgs",
    "outputId": "c57fff4e-b216-440e-a15a-2f9a2d4b2097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
      "This share link will expire in 6 hours. If you need a permanent link, email support@gradio.app\n",
      "Running on External URL: https://39815.gradio.app\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"https://39815.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdf994f5e80>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gr.Interface(classify_image, image, label, capture_session=True, interpretation=integrated_smoothgrad, examples=examples,\n",
    "             allow_flagging=False).launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqBRK0c-2947"
   },
   "source": [
    "### Blur Integrated Gradients [2020]\n",
    "\n",
    "Paper: [Attribution in Scale and Space (2020)](https://arxiv.org/pdf/2004.03383)\n",
    "\n",
    "**Note**: This method is *very* slow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "GSAVftoh5GQ3",
    "outputId": "0837e9e8-d789-4f04-f568-f976630212a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "This share link will expire in 6 hours. If you need a permanent link, email support@gradio.app\n",
      "Running on External URL: https://21482.gradio.app\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"https://21482.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdf995ee550>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>,\n",
       " 'http://127.0.0.1:7871/',\n",
       " 'https://21482.gradio.app')"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(classify_image, image, label, capture_session=True, interpretation=blur_IG_vanilla, examples=examples,\n",
    "             allow_flagging=False).launch()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "History-of-Interpretation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
